{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note- This content is copyrighted material:  \n",
    "CC-BY Attribution 4.0 International Lynd Bacon & Associates, Ltd. DBA Loma Buena Associates www.LBA.com  \n",
    "For information on permissible use, see https://creativecommons.org/licenses/by-sa/4.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will prepare some TripAdvisor customer review data for brand positioning analyses.  The data are of two kinds, numerical ratings that reviewers gave to hotels they stayed in, and things they said about their hotels in the form of text data.  \n",
    "\n",
    "The kind of analysis that the data you'll prepare will be used for is called _perceptual mapping_.  Different kinds of analytic methods are used to do perceptual mapping, but the basic objective is to use data on customers' perceptions to represent brands in a low-dimensional space (a \"map\") that can be interpreted based on important brand differences.  Different kinds of data can be used to do it.  In this GrEx you'll prepare both numerical data and also text data for it.\n",
    "\n",
    "The data is in some number json files.  Each file contains data for one hotel.  The json files are archived in the zip file `hotelCustsSu2017.zip`.\n",
    "\n",
    "This GrEx is in two parts.  Part 1 is about getting the numeric ratings data ready, and Part 2 is about readying the text data.\n",
    "\n",
    "These data have been made available by the resarchers of the LARA project, http://www.cs.virginia.edu/~hw5x/dataset.html  \n",
    "\n",
    "A lot of this GrEx has to do with Python `dictionaries,` or \"dicts.\"  If you're completely new to dicts, you may want to spend a few minutes reviewing what's in the course readings or is online about them.  There are \"plain vanilla,\" or \"everyday\" dicts, and some specializations can be found in the Python `collections` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter: Get a Look At Some of The Hotel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the zip file with the data in it, and extract the json files in it.  Then, in a Python session or in a Jupyter Notebook, read what's in the hotel file 100506.json.  Here's a way to do it.  First, import the `json` package. Then, assuming that the file is in your current working directory,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('100506.json') as input_file:\n",
    "    jsondat=json.load(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at `jsondat`.  You see that it consists of nested dictionaries.  As you may know, Python dictionaries hold things in key:value pairs. The values in a dictionary can be other dictionaries, lists, scalars (single numbers), pandas DataFrames and Series, and other things.  The key is a label for the thing. \n",
    "\n",
    "Is `jsondat` itself actually a dictionary?  Try `type(jsondat)` to see.   What are the keys in `jsondat`, and what types are they?  Extact each of the key:value pairs from `jsondat` and check to see what kinds of Python objects they are.  You should find something about hotel information, and another thing about hotel reviews.  The latter includes whatever reviews have been provided for this particular hotel.  Examine what's in the reviews data. There may be ratings on various scales, and also comments that reviewers may have made when they posted their reviews.\n",
    "\n",
    "Bear in mind that what's in any hotel data file may vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the json Files for Perceptual Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both parts of this GrEx you'll need to read the hotel data files into Python (or Jupyter) for processing.  You'll want to read the files in one at a time, process what's in the file read, and then move on to reading and processing the next file.  You can load what's in each file using code like the above.  Note the use of the 'with open' idiom.  When you read (or write) a file using it, the file is automatically closed when the with clause ends.  \n",
    "\n",
    "There are a couple of ways you can specify the files to be read, but you'll want to read them using a loop of some kind, and in the loop you'll do the processing of each file.\n",
    "\n",
    "Something to be aware of from the start is that the hotel files don't all have exactly the same contents, and the reviewers of the hotels didn't necessarily provide the same ratings.  It's possible that some hotel files may not have any reviews at all, so you'll need to be sure that your code can handle such possibilities.  (Hint: Do you know about Python `Try` and `Except`?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Numeric Peceptual Mapping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will use the data in the json files to create a new data set.  \n",
    "\n",
    "(a) Build it as a `pandas` DataFrame.  Your DataFrame should have a row for each hotel review, and the following columns in it:\n",
    "\n",
    "> Hotel ID  \n",
    "> Hotel Name  \n",
    "> Review Date  \n",
    "> Review ID \n",
    "> Author Name  \n",
    "> Each rating given by the reviewer in its own column\n",
    "\n",
    "Your DataFrame should have at least one row for every hotel.  Hotel name, Review ID, and Auther name should be string type variables.  Review date can also be a string. The other columns should be numeric.  Use an appropriate code to represent missing values. \n",
    "\n",
    "(b) Report the number of reviews for each hotel in the DataFrame.\n",
    "\n",
    "(b) Calculate and report statistics describing the distribution of the overall rating received by the hotels.  (This is across all the hotels, not for each hotel separately.)\n",
    "\n",
    "(c) Save your DataFrame by pickling it, and verify that your DataFrame was saved correctly.  Be sure to save it as you may be asked to share it with the class later in the course.\n",
    "\n",
    "Some find using `pandas.io.json.json_normalize` to be helpful for converting json objects into DataFrame type objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Text Data for Perceptual Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the fun part of this GrEx. It's time to get dirty with some text data.\n",
    "\n",
    "Each hotel review may include text that the reviewing author wrote.  You are going to create a json file that includes for each hotel a dictionary summarizing the \"content\" words in the authors' text.  This text is the value of the \"Content\" key in a review.\n",
    "\n",
    "You want to process the written comments for each hotel, one hotel at a time, to put the number of times each \"content\" word occurs in the comments into a dict.  This dict should have the words as keys, and the counts of the times they occur as the values of the keys.  For example, suppose the word 'bathroom' occurs 50 times in the comments for a hotel.  Then the dict of words for this hotel would have a key of 'bathroom', and the value associated with it would be 50.\n",
    "\n",
    "A \"content\" word is a word that carries meaning, and that is not a _stop word_.   _Stop words_ are words like prepositions that are often removed when doing text mining or natural language processing (NLP).  They are a \"fuzzy set\" in that there's no universally agreed upon set of them.  See https://en.wikipedia.org/wiki/Stop_words for a bit about them.\n",
    "\n",
    "To build your dictionary of content word counts for a hotel, you need to exclude stop words, and also any other things like html tags and puncuation marks.  Python resources you can use for this include the `string`, `Beautiful Soup`, `stop-words`, and (perhaps) `urllib` packages. (`nltk`, too if you're feeling adventurous or if you're familiar with it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's a way you might approach the task for creating a content word count dictionary for a hotel.  You might decide to do it in a different way, of course.\n",
    "\n",
    "> 1 Create one big long string of the contents of comments about the hotel.  \n",
    "> 2 Clean the string of all html tags, punctuation, and other \"non-word\" stuff.  This should leave you with a string of words separated by spaces. You might want to remove digits, too.\n",
    "\n",
    "(Note: there can always be anomalies to contend with when pounding text data into 'submission.'  And head-scratchers to be resolved, too. For exsample, what should be do about apostrophes, like in \"we'll?\" Oh, well...)\n",
    "\n",
    "> 3 Convert the string to a list of words by spltting the string on spaces.  \n",
    "> 4 Remove all stop words from the list, leaving in it your \"content\" words.\n",
    "> 5 If you're feeling adventurous, you might want to do word stemming, as well, e.g. using the `stemming` package or some other resource. (See https://en.wikipedia.org/wiki/Stemming about stemming if you're interested.)  \n",
    "> 6 Create a dict fom the list in which the keys are the \"content\" words, and their values are the number of times each word occurs.   \n",
    "(Hint: Think about iterating through your list to build up your dict.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating the json file of hotel word dictionaries__\n",
    "\n",
    "Once you've done the above for a hotel's comments, you need to add it to a dict that you'll save as a json file.  This dict will be a \"dict of dicts\".  Each of the dicts in it will have your dict of word counts for a hotel as the value, and it's key in your \"dict of dicts\" will be the hotel's ID, which is a number.\n",
    "\n",
    "Imagine that you name your \"dict of dicts\" `hotWords`.  The keys in `hotWords` would be the hotel IDs. The value associated with each hotel ID key is a hotel's content word count dictionary.\n",
    "\n",
    "Got that?\n",
    "\n",
    "`hotWords.keys()` would have hotel IDs in it. (What type is `hotWords`?  What about `hotWords.keys()`? )\n",
    "\n",
    "Each of the hotel ID keys in `hotWords.keys()` would have a dict of words and word counts as its value, assuming of course that any comments were made about the hotel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, here's what you need to do for Part 2:\n",
    "\n",
    "> 1. Create for each hotel a dict of comment content words and their frequencies, the counts of their occurrences.\n",
    "> 2. Add each of the hotel content word dicts to a dict with their hotel IDs as the keys.\n",
    "> 3. Write this dict to a json file, and verify that it is written correctly.\n",
    "> 4. Report the number of unique content words in each of the hotel's dicts. (Unique content words, not how many times the words occurred.)\n",
    "\n",
    "Be sure to save your the json file you \"serialized\" as you may be asked to share it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In _no more than seven (7) pages_, and in a single pdf file, provide the following.\n",
    "\n",
    "Provide your commented, syntactically correct code for each step you took to create the results described.\n",
    "\n",
    "Be sure to save the data files you created.\n",
    "\n",
    "For each of the steps above, provide commented, syntactically correct code.  Do _not_ submit all of your code for this assigment in a single block, followed by a block of all of your output.   __Assignments organized in this manner will not be graded.__\n",
    "\n",
    "Your assignment will be graded as described in the GrEx Assignment Grading Jupyter Notebook on Canvas."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
